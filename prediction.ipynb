{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcecdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from PPI_prediction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ensg_id()\n",
    "uniprot_request()\n",
    "make_ensp_ensg()\n",
    "make_interaction_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_protbert_embedding()\n",
    "make_prott5_embedding()\n",
    "make_esm_embedding('esm1b')\n",
    "make_esm_embedding('esm2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c578d0f",
   "metadata": {},
   "source": [
    "embedding_fname을 수정하여 각 임베딩에 접근하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae26ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_fname = 'HI-union.tsv'\n",
    "sub_interaction_fname = 'STRING_interactions.txt'\n",
    "sequence_fname = 'HI_union_Uniprot_Sequence2.txt'\n",
    "fname = [\n",
    "    \"biomedical/HI_union_protbert_embeddings.npz\",\n",
    "    \"biomedical/HI_union_protT5_embeddings.npz\",\n",
    "    \"biomedical/HI_union_esm1b_650M_embeddings.npz\",\n",
    "    \"biomedical/HI_union_esm2_650M_embeddings.npz\"\n",
    "]\n",
    "embedding_fname = fname[0]\n",
    "pca = 0\n",
    "norm = False\n",
    "\n",
    "graph_data2 = make_graph(\n",
    "    sequence_fname, \n",
    "    interaction_fname, \n",
    "    sub_interaction_fname,\n",
    "    embedding_fname,\n",
    "    pca,\n",
    "    norm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = spilt_data(graph_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7fb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'GCN'\n",
    "if pca:\n",
    "    if 'esm1b' in embedding_fname:\n",
    "        fname = 'log_esm1b_' + model + '_pca'+pca+'.txt'\n",
    "        best_model = 'log_esm1b_' + model +'_best_pca'+pca+'.pt'\n",
    "    elif 'esm2' in embedding_fname:\n",
    "        fname = 'log_esm2_' + model + '_pca'+pca+'.txt'\n",
    "        best_model = 'log_esm2_' + model +'_best_pca'+pca+'.pt'\n",
    "    elif 'T5' in embedding_fname:\n",
    "        fname = 'log_ProtT5_' + model + '_pca'+pca+'.txt'\n",
    "        best_model = 'log_ProtT5_' + model +'_best_pca'+pca+'.pt'\n",
    "    elif 'bert' in embedding_fname:\n",
    "        fname = 'log_ProtBERT_' + model + '_pca'+pca+'.txt'\n",
    "        best_model = 'log_ProtBERT_' + model +'_best_pca'+pca+'.pt'\n",
    "elif norm:\n",
    "    if 'esm1b' in embedding_fname:\n",
    "        fname = 'log_esm1b_' + model + '_norm.txt'\n",
    "        best_model = 'log_esm1b_' + model +'_best_norm.pt'\n",
    "    elif 'esm2' in embedding_fname:\n",
    "        fname = 'log_esm2_' + model + '_norm.txt'\n",
    "        best_model = 'log_esm2_' + model +'_best_norm.pt'\n",
    "    elif 'T5' in embedding_fname:\n",
    "        fname = 'log_ProtT5_' + model + '_norm.txt'\n",
    "        best_model = 'log_ProtT5_' + model +'_best_norm.pt'\n",
    "    elif 'bert' in embedding_fname:\n",
    "        fname = 'log_ProtBERT_' + model + '_norm.txt'\n",
    "        best_model = 'log_ProtBERT_' + model +'_best_norm.pt'\n",
    "else:\n",
    "    if 'esm1b' in embedding_fname:\n",
    "        fname = 'log_esm1b_' + model + '.txt'\n",
    "        best_model = 'log_esm1b_' + model +'_best.pt'\n",
    "    elif 'esm2' in embedding_fname:\n",
    "        fname = 'log_esm2_' + model + '.txt'\n",
    "        best_model = 'log_esm2_' + model +'_best.pt'\n",
    "    elif 'T5' in embedding_fname:\n",
    "        fname = 'log_ProtT5_' + model + '.txt'\n",
    "        best_model = 'log_ProtT5_' + model +'_best.pt'\n",
    "    elif 'bert' in embedding_fname:\n",
    "        fname = 'log_ProtBERT_' + model + '.txt'\n",
    "        best_model = 'log_ProtBERT_' + model +'_best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1195bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "\n",
    "in_channel = graph_data2.x.shape[1]\n",
    "state_record = {}\n",
    "top, best_val, early_stop, best_epoch = 0, 0, 0, 0\n",
    "\n",
    "home = os.path.expanduser(\"~\")\n",
    "model_file = os.path.join(home, 'biomedical', 'log_data', best_model)\n",
    "target = os.path.join(home, 'biomedical', 'log_data', fname)\n",
    "f = open(target, 'w')\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    print(i)\n",
    "    hidden, layers, out, rate, drop, decay = hyperparameter_tuning(in_channel)\n",
    "    f.write(f\"\\nIn: {in_channel} | Hidden: {hidden:3d} | Layers: {layers:2d} | Out: {out:3d} | Rate: {rate:.4f} | Drop: {drop:.2f} | Decay: {decay:.5f}\\n\")\n",
    "    f.flush()\n",
    "    key = (hidden, layers, out, rate, drop, decay)\n",
    "    state_record[key] = [[], []]  # loss, val_f1\n",
    "\n",
    "\n",
    "    pred_model, optimizer = set_model(in_channel, *key, model)\n",
    "\n",
    "    for epoch in range(1, 301):\n",
    "\n",
    "        loss = train(pred_model, optimizer, train_data)   \n",
    "        # 각 epoch마다 train data로 학습을 진행함\n",
    "\n",
    "        val_f1 = evaluate(pred_model, val_data, train_data, True)['f1']   \n",
    "        # 각 epoch마다 validation data로 검증 진행\n",
    "\n",
    "        state_record[key][0].append(loss)\n",
    "        state_record[key][1].append(val_f1)\n",
    "        if val_f1 > best_val:\n",
    "            best_val = val_f1\n",
    "            early_stop = 0\n",
    "        else:\n",
    "            early_stop += 1\n",
    "            if early_stop >= 20:\n",
    "                break\n",
    "\n",
    "        if top < best_val:\n",
    "            top = best_val\n",
    "            best_epoch = epoch\n",
    "            torch.save(pred_model.state_dict(), model_file)\n",
    "        \n",
    "        print(f\"Epoch {epoch:3d} | Loss: {loss:.4f} | Val: {val_f1:.4f} | Best: {best_val:.4f}\")\n",
    "        print(f\"Epoch {epoch:3d} | Loss: {loss:.4f} | Val: {val_f1:.4f} | Best: {best_val:.4f}\", file=f)\n",
    "        f.flush()\n",
    "    best_val = 0\n",
    "\n",
    "\n",
    "\n",
    "# 최종 테스트\n",
    "for key, value in state_record.items():\n",
    "    if max(value[1]) == top:\n",
    "        loss = value[0]\n",
    "        f1 = value[1]\n",
    "        param = key\n",
    "\n",
    "pred_model, optimizer = set_model(in_channel, *param, model)\n",
    "pred_model.load_state_dict(torch.load(model_file))\n",
    "test_f1 = evaluate(pred_model, test_data, train_data, True)\n",
    "f.write(\" | \".join(map(str, param)))\n",
    "print(f\"TEST | Best Val : {top:.4f} (Epoch {best_epoch}) | Test AUC: {test_f1['auc']:.4f} | Test F1: {test_f1['f1']:.4f} | Test Accuracy: {test_f1['accuracy']:.4f}\", file = f)\n",
    "print(f\"\\nBest Val : {top:.4f} (Epoch {best_epoch})\")\n",
    "print(f\"Test AUC:     {test_f1['auc']:.4f}\")\n",
    "print(f\"Test F1:      {test_f1['f1']:.4f}\")\n",
    "print(f\"Test Accuracy: {test_f1['accuracy']:.4f}\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key, value in state_record.items():\n",
    "    if max(value[1]) == top:\n",
    "        loss = value[0]\n",
    "        f1 = value[1]\n",
    "        hidden, layers, out, rate, drop = key\n",
    "\n",
    "x = list(range(1, len(loss)+1))\n",
    "\n",
    "plt.plot(x, loss, label='Loss', marker='o')\n",
    "plt.plot(x, f1, label='F1', marker='x')\n",
    "plt.title(f'Hidden: {hidden}, Layers: {layers}, Out: {out}, Rate: {rate}, Drop: {drop}')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Evaluation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0150053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외부 데이터로 시험\n",
    "\n",
    "for key, value in state_record.items():\n",
    "    if max(value[1]) == top:\n",
    "        loss = value[0]\n",
    "        f1 = value[1]\n",
    "        hidden, layers, out, rate, drop = key\n",
    "\n",
    "pred_model, optimizer = GCN.set_model(in_channel, hidden, layers, out, rate, drop)\n",
    "pred_model.load_state_dict(torch.load('best.pt'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df736e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
